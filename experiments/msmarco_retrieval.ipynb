{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS MARCO Retrieval Pipeline with Permutation Self-Consistency\n",
    "\n",
    "This notebook demonstrates the full retrieval pipeline:\n",
    "1. Initial retrieval using BM25 or SPLADE++\n",
    "2. Optional LLM reranking with permutation self-consistency\n",
    "3. Evaluation on TREC DL19/20 datasets using NDCG and MRR metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set JAVA_HOME to: /usr/local/Cellar/openjdk@11/11.0.29/libexec/openjdk.jdk/Contents/Home\n",
      "Java version: openjdk version \"11.0.29\" 2025-10-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Cellar/python@3.10/3.10.19_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.19_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.19_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.19_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.19_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/lv/3b31xxlx2vg_ntbjdr6b2rtm0000gn/T/ipykernel_12827/4079920732.py\", line 41, in <module>\n",
      "    from permsc.retrieval import (\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/permsc/__init__.py\", line 7, in <module>\n",
      "    from .retrieval import *\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/permsc/retrieval/__init__.py\", line 2, in <module>\n",
      "    from .retrievers import BaseRetriever, BM25Retriever, SpladeRetriever\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/permsc/retrieval/retrievers.py\", line 8, in <module>\n",
      "    from sentence_transformers import SentenceTransformer\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/sentence_transformers/__init__.py\", line 10, in <module>\n",
      "    from sentence_transformers.backend import (\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/sentence_transformers/backend/__init__.py\", line 3, in <module>\n",
      "    from .load import load_onnx_model, load_openvino_model\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/sentence_transformers/backend/load.py\", line 7, in <module>\n",
      "    from transformers.configuration_utils import PretrainedConfig\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/transformers/__init__.py\", line 27, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/transformers/utils/__init__.py\", line 24, in <module>\n",
      "    from .auto_docstring import (\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/transformers/utils/auto_docstring.py\", line 30, in <module>\n",
      "    from .generic import ModelOutput\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/transformers/utils/generic.py\", line 51, in <module>\n",
      "    import torch\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/arul/Documents/diff-perm-sc/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set JAVA_HOME for Pyserini (required for BM25 retrieval)\n",
    "# This ensures Java 11+ is used even if Jupyter doesn't inherit shell environment\n",
    "if 'JAVA_HOME' not in os.environ or '1.8' in os.popen('java -version 2>&1').read():\n",
    "    # Try to find Java 11+ via Homebrew\n",
    "    java_home_candidates = [\n",
    "        '/usr/local/Cellar/openjdk@11/11.0.29/libexec/openjdk.jdk/Contents/Home',\n",
    "        '/usr/local/Cellar/openjdk@17/17.0.13/libexec/openjdk.jdk/Contents/Home',\n",
    "        '/opt/homebrew/opt/openjdk@11/libexec/openjdk.jdk/Contents/Home',\n",
    "        '/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home',\n",
    "    ]\n",
    "    \n",
    "    for candidate in java_home_candidates:\n",
    "        if os.path.exists(candidate):\n",
    "            os.environ['JAVA_HOME'] = candidate\n",
    "            os.environ['PATH'] = f\"{candidate}/bin:{os.environ.get('PATH', '')}\"\n",
    "            print(f\"Set JAVA_HOME to: {candidate}\")\n",
    "            break\n",
    "    else:\n",
    "        # Fallback: try to use java_home utility\n",
    "        try:\n",
    "            import subprocess\n",
    "            java_home = subprocess.check_output(['/usr/libexec/java_home', '-v', '11+']).decode().strip()\n",
    "            os.environ['JAVA_HOME'] = java_home\n",
    "            os.environ['PATH'] = f\"{java_home}/bin:{os.environ.get('PATH', '')}\"\n",
    "            print(f\"Set JAVA_HOME to: {java_home}\")\n",
    "        except:\n",
    "            print(\"Warning: Could not set JAVA_HOME automatically. Pyserini may not work.\")\n",
    "            print(\"Please ensure Java 11+ is installed and JAVA_HOME is set correctly.\")\n",
    "\n",
    "# Verify Java version\n",
    "if 'JAVA_HOME' in os.environ:\n",
    "    java_version = os.popen(f\"{os.environ['JAVA_HOME']}/bin/java -version 2>&1\").read()\n",
    "    print(f\"Java version: {java_version.split(chr(10))[0]}\")\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from permsc.retrieval import (\n",
    "    MSMarcoQueries, MSMarcoCollection, TRECQrels,\n",
    "    BM25Retriever, SpladeRetriever, RetrievalPipeline,\n",
    "    evaluate_retrieval\n",
    ")\n",
    "from permsc.llm.openai_pool import OpenAIConfig\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up paths and configuration. Update these paths to match your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: ../data\n",
      "Using prebuilt index: msmarco-v1-passage (will download if needed)\n",
      "OpenAI API key set: False\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "MSMARCO_COLLECTION = DATA_DIR / \"msmarco/collection.tsv\"\n",
    "TREC_DL19_QUERIES = DATA_DIR / \"trec-dl19/msmarco-test2019-queries.tsv\"\n",
    "TREC_DL19_QRELS = DATA_DIR / \"trec-dl19/2019qrels-pass.txt\"\n",
    "TREC_DL20_QUERIES = DATA_DIR / \"trec-dl20/msmarco-test2020-queries.tsv\"\n",
    "TREC_DL20_QRELS = DATA_DIR / \"trec-dl20/2020qrels-pass.txt\"\n",
    "\n",
    "# BM25 Index Configuration\n",
    "# Option 1: Use prebuilt index (downloads automatically - recommended)\n",
    "USE_PREBUILT_INDEX = True\n",
    "PREBUILT_INDEX_NAME = \"msmarco-v1-passage\"\n",
    "\n",
    "# Option 2: Use local index path (if you have downloaded it manually)\n",
    "# USE_PREBUILT_INDEX = False\n",
    "# BM25_INDEX_PATH = \"indexes/msmarco-passage/lucene-index.msmarco-v1-passage.20221004.252b5e\"\n",
    "\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "if USE_PREBUILT_INDEX:\n",
    "    print(f\"Using prebuilt index: {PREBUILT_INDEX_NAME} (will download if needed)\")\n",
    "else:\n",
    "    print(f\"BM25 index path: {BM25_INDEX_PATH}\")\n",
    "print(f\"OpenAI API key set: {bool(OPENAI_API_KEY)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MS MARCO collection...\n",
      "Collection loaded: 8841823 passages\n",
      "\n",
      "Loading TREC DL19 queries and qrels...\n",
      "DL19: 200 queries, 43 queries with qrels\n",
      "\n",
      "Loading TREC DL20 queries and qrels...\n",
      "DL20: 200 queries, 54 queries with qrels\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading MS MARCO collection...\")\n",
    "collection = MSMarcoCollection(str(MSMARCO_COLLECTION))\n",
    "print(f\"Collection loaded: {len(collection)} passages\")\n",
    "\n",
    "print(\"\\nLoading TREC DL19 queries and qrels...\")\n",
    "dl19_queries = MSMarcoQueries(str(TREC_DL19_QUERIES))\n",
    "dl19_qrels = TRECQrels(str(TREC_DL19_QRELS))\n",
    "print(f\"DL19: {len(dl19_queries)} queries, {len(dl19_qrels)} queries with qrels\")\n",
    "\n",
    "print(\"\\nLoading TREC DL20 queries and qrels...\")\n",
    "dl20_queries = MSMarcoQueries(str(TREC_DL20_QUERIES))\n",
    "dl20_qrels = TRECQrels(str(TREC_DL20_QRELS))\n",
    "print(f\"DL20: {len(dl20_queries)} queries, {len(dl20_qrels)} queries with qrels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Retrievers\n",
    "\n",
    "Choose which retriever to use: BM25 or SPLADE++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BM25 retriever with prebuilt index: msmarco-v1-passage\n",
      "Retriever initialized successfully\n"
     ]
    }
   ],
   "source": [
    "RETRIEVER_TYPE = \"bm25\"  # or \"splade\"\n",
    "\n",
    "if RETRIEVER_TYPE == \"bm25\":\n",
    "    if USE_PREBUILT_INDEX:\n",
    "        print(f\"Initializing BM25 retriever with prebuilt index: {PREBUILT_INDEX_NAME}\")\n",
    "        retriever = BM25Retriever(prebuilt_index=PREBUILT_INDEX_NAME)\n",
    "    else:\n",
    "        print(f\"Initializing BM25 retriever with local index: {BM25_INDEX_PATH}\")\n",
    "        retriever = BM25Retriever(index_path=BM25_INDEX_PATH)\n",
    "elif RETRIEVER_TYPE == \"splade\":\n",
    "    print(\"Initializing SPLADE++ retriever...\")\n",
    "    retriever = SpladeRetriever(str(MSMARCO_COLLECTION))\n",
    "else:\n",
    "    raise ValueError(f\"Unknown retriever type: {RETRIEVER_TYPE}\")\n",
    "\n",
    "print(\"Retriever initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup LLM Reranking (Optional)\n",
    "\n",
    "If API key is provided, LLM reranking with permutation self-consistency will be enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API key provided. LLM reranking disabled.\n",
      "No LLM config provided or API key missing. LLM reranking will be disabled.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "llm_config = None\n",
    "if OPENAI_API_KEY:\n",
    "    llm_config = OpenAIConfig(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        api_type=\"openai\"\n",
    "    )\n",
    "    print(\"LLM reranking enabled\")\n",
    "else:\n",
    "    print(\"No API key provided. LLM reranking disabled.\")\n",
    "\n",
    "pipeline = RetrievalPipeline(\n",
    "    retriever=retriever,\n",
    "    collection=collection,\n",
    "    llm_config=llm_config,\n",
    "    num_permutations=5,\n",
    "    aggregator=\"kemeny\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Retrieval and Evaluation\n",
    "\n",
    "Run the pipeline on TREC DL19/20 queries and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running retrieval on DL19 (50 queries)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def run_evaluation(queries, qrels, dataset_name, max_queries=None):\n",
    "    \"\"\"Run retrieval pipeline and evaluate on a dataset.\"\"\"\n",
    "    query_ids = list(queries.get_all_queries().keys())\n",
    "    if max_queries:\n",
    "        query_ids = query_ids[:max_queries]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(f\"\\nRunning retrieval on {dataset_name} ({len(query_ids)} queries)...\")\n",
    "    for query_id in tqdm(query_ids):\n",
    "        query_text = queries.get_query(query_id)\n",
    "        if not query_text:\n",
    "            continue\n",
    "        \n",
    "        ranking_example = pipeline.run(query_text, top_k=1000, rerank_depth=100)\n",
    "        results[query_id] = ranking_example\n",
    "    \n",
    "    print(f\"\\nEvaluating {dataset_name}...\")\n",
    "    metrics = evaluate_retrieval(results, qrels.get_all_qrels(), k_values=[10, 100])\n",
    "    \n",
    "    return metrics, results\n",
    "\n",
    "metrics_dl19, results_dl19 = run_evaluation(dl19_queries, dl19_qrels, \"DL19\", max_queries=50)\n",
    "metrics_dl20, results_dl20 = run_evaluation(dl20_queries, dl20_qrels, \"DL20\", max_queries=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Dataset': ['DL19', 'DL20'],\n",
    "    'NDCG@10': [metrics_dl19['ndcg@10'], metrics_dl20['ndcg@10']],\n",
    "    'NDCG@100': [metrics_dl19['ndcg@100'], metrics_dl20['ndcg@100']],\n",
    "    'MRR': [metrics_dl19['mrr'], metrics_dl20['mrr']]\n",
    "})\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nRetriever: {RETRIEVER_TYPE.upper()}\")\n",
    "print(f\"LLM Reranking: {'Enabled' if llm_config else 'Disabled'}\")\n",
    "if llm_config:\n",
    "    print(f\"Permutations: {pipeline.num_permutations}\")\n",
    "    print(f\"Aggregator: {pipeline.aggregator_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics_to_plot = ['NDCG@10', 'NDCG@100', 'MRR']\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx]\n",
    "    values = results_df[metric].values\n",
    "    ax.bar(results_df['Dataset'], values, color=['#3498db', '#e74c3c'])\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f'{metric} by Dataset')\n",
    "    ax.set_ylim(0, max(values) * 1.2)\n",
    "    \n",
    "    for i, v in enumerate(values):\n",
    "        ax.text(i, v + max(values) * 0.02, f'{v:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different Configurations\n",
    "\n",
    "To compare BM25 vs SPLADE++ or with/without LLM reranking, run the cells above with different configurations and compare the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
